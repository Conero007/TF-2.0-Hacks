{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "tf.keras blog post code samples.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdlJ__2jj3HY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMjHa-MYj1CK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2030120d-44e3-4820-e080-26ec21aab88f"
      },
      "source": [
        "# Checks and setup\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoJYH1MRj1CP",
        "colab_type": "text"
      },
      "source": [
        "## Eager execution\n",
        "\n",
        "Since eager execution is enabled by default in TensorFlow 2.0 you _do not_ need to do anything to enable it. However, you can disable it by executing the following:\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "```\n",
        "\n",
        "If you want to know whether eager execution is enabled or not just execute `tf.executing_eagerly()`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb_vsZ1xj1CQ",
        "colab_type": "text"
      },
      "source": [
        "## GradientTape\n",
        "\n",
        "## Part I"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXUaXZjxj1CS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0bfc5350-184c-4098-958a-fe3b02d28a71"
      },
      "source": [
        "a = tf.Variable(tf.random.normal(shape=(2, 2)))\n",
        "b = tf.random.normal(shape=(2, 2))\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    c = tf.sqrt(tf.square(a) + tf.square(b))  \n",
        "    # Gradient of `c` w.r.t `a`\n",
        "    dc_da = tape.gradient(c, a)\n",
        "    print(dc_da)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.76125926 -0.8547008 ]\n",
            " [-0.95074195  0.8155739 ]], shape=(2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXsghVMAj1CV",
        "colab_type": "text"
      },
      "source": [
        "## Part II"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN0kBQWkj1CW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9teeZa6j1CZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aaeb4b01-fcf9-4b6e-edd4-32d9493dbd1d"
      },
      "source": [
        "# Generate some data\n",
        "X, y = make_blobs(n_samples=100, centers=2, n_features=2,\n",
        "                  random_state=666)\n",
        "\n",
        "X.shape, y.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 2), (100,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRlAp4Oxj1Cc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "96a7715c-c446-4b8a-f46e-8b5785355d61"
      },
      "source": [
        "X[:10], y[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[2.34769665, 3.84737956],\n",
              "        [2.25211721, 7.72836548],\n",
              "        [4.20334204, 8.19437057],\n",
              "        [4.56840252, 5.00758839],\n",
              "        [5.14209854, 8.60577994],\n",
              "        [5.3476516 , 4.49482029],\n",
              "        [0.77015549, 4.84023746],\n",
              "        [3.93882207, 7.52922765],\n",
              "        [4.41391444, 2.56506757],\n",
              "        [3.40315224, 8.62298395]]), array([1, 0, 0, 1, 0, 1, 1, 0, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZYKCA5Pj1Cf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "cdd403a7-c07f-4f2d-86ee-675e27f1fed8"
      },
      "source": [
        "# Plot the data\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y.reshape((100,1))[:, 0])\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRKGHEEIlotBDCKESfwEDXjMFNuMKtAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDkahkQ-j1Ch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a model to fit the above data\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dropout(rate=0.2, input_shape=X.shape[1:]),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWpLN2pvj1Cl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss and optimizer\n",
        "loss_func = tf.keras.losses.BinaryCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAclaOGvj1Co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_loop(features, labels):\n",
        "    # Define the GradientTape context\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Get the probabilities\n",
        "        predictions = model(features)\n",
        "        # Calculate the loss\n",
        "        loss = loss_func(labels, predictions)\n",
        "    # Get the gradients\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    # Update the weights\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkqyX3mQj1Cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffle the data\n",
        "indices = np.random.permutation(len(X))\n",
        "features = X[indices]\n",
        "labels = y[indices]\n",
        "\n",
        "# Create batches of data\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7dklDdOj1Cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "def train_model():\n",
        "    start = time.time()\n",
        "    for epoch in range(10):\n",
        "        for step, (x, y) in enumerate(dataset):\n",
        "            loss = train_loop(x, y)\n",
        "            print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))\n",
        "    print(\"It took {} seconds\".format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLW1G4ZAj1Cx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e1ed840-2772-4d10-bb89-c87111666549"
      },
      "source": [
        "train_model()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer dropout is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "Epoch 0: last batch loss = 0.8985\n",
            "Epoch 0: last batch loss = 0.6993\n",
            "Epoch 0: last batch loss = 0.8309\n",
            "Epoch 0: last batch loss = 0.7734\n",
            "Epoch 0: last batch loss = 0.7254\n",
            "Epoch 0: last batch loss = 0.7579\n",
            "Epoch 0: last batch loss = 0.7253\n",
            "Epoch 1: last batch loss = 0.6860\n",
            "Epoch 1: last batch loss = 0.7291\n",
            "Epoch 1: last batch loss = 0.7001\n",
            "Epoch 1: last batch loss = 0.7077\n",
            "Epoch 1: last batch loss = 0.6907\n",
            "Epoch 1: last batch loss = 0.6767\n",
            "Epoch 1: last batch loss = 0.6743\n",
            "Epoch 2: last batch loss = 0.6471\n",
            "Epoch 2: last batch loss = 0.6815\n",
            "Epoch 2: last batch loss = 0.6705\n",
            "Epoch 2: last batch loss = 0.6742\n",
            "Epoch 2: last batch loss = 0.6932\n",
            "Epoch 2: last batch loss = 0.7018\n",
            "Epoch 2: last batch loss = 0.6571\n",
            "Epoch 3: last batch loss = 0.6307\n",
            "Epoch 3: last batch loss = 0.7645\n",
            "Epoch 3: last batch loss = 0.6136\n",
            "Epoch 3: last batch loss = 0.6839\n",
            "Epoch 3: last batch loss = 0.6087\n",
            "Epoch 3: last batch loss = 0.7115\n",
            "Epoch 3: last batch loss = 0.5701\n",
            "Epoch 4: last batch loss = 0.7022\n",
            "Epoch 4: last batch loss = 0.5887\n",
            "Epoch 4: last batch loss = 0.6585\n",
            "Epoch 4: last batch loss = 0.6350\n",
            "Epoch 4: last batch loss = 0.6707\n",
            "Epoch 4: last batch loss = 0.6822\n",
            "Epoch 4: last batch loss = 0.6470\n",
            "Epoch 5: last batch loss = 0.5452\n",
            "Epoch 5: last batch loss = 0.6551\n",
            "Epoch 5: last batch loss = 0.6540\n",
            "Epoch 5: last batch loss = 0.6886\n",
            "Epoch 5: last batch loss = 0.7195\n",
            "Epoch 5: last batch loss = 0.6443\n",
            "Epoch 5: last batch loss = 0.5006\n",
            "Epoch 6: last batch loss = 0.6292\n",
            "Epoch 6: last batch loss = 0.5951\n",
            "Epoch 6: last batch loss = 0.6177\n",
            "Epoch 6: last batch loss = 0.6193\n",
            "Epoch 6: last batch loss = 0.5972\n",
            "Epoch 6: last batch loss = 0.7221\n",
            "Epoch 6: last batch loss = 0.7308\n",
            "Epoch 7: last batch loss = 0.6110\n",
            "Epoch 7: last batch loss = 0.6018\n",
            "Epoch 7: last batch loss = 0.6233\n",
            "Epoch 7: last batch loss = 0.6046\n",
            "Epoch 7: last batch loss = 0.6437\n",
            "Epoch 7: last batch loss = 0.6323\n",
            "Epoch 7: last batch loss = 0.7152\n",
            "Epoch 8: last batch loss = 0.5957\n",
            "Epoch 8: last batch loss = 0.5999\n",
            "Epoch 8: last batch loss = 0.6144\n",
            "Epoch 8: last batch loss = 0.6171\n",
            "Epoch 8: last batch loss = 0.6093\n",
            "Epoch 8: last batch loss = 0.6599\n",
            "Epoch 8: last batch loss = 0.6276\n",
            "Epoch 9: last batch loss = 0.6311\n",
            "Epoch 9: last batch loss = 0.6428\n",
            "Epoch 9: last batch loss = 0.5996\n",
            "Epoch 9: last batch loss = 0.6139\n",
            "Epoch 9: last batch loss = 0.5884\n",
            "Epoch 9: last batch loss = 0.6062\n",
            "Epoch 9: last batch loss = 0.5989\n",
            "It took 1.6045215129852295 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1hQmytpj1C4",
        "colab_type": "text"
      },
      "source": [
        "## Without `tf.function`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1stOFP7j1C6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_loop(features, labels):\n",
        "    # Define the GradientTape context\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Get the probabilities\n",
        "        predictions = model(features)\n",
        "        # Calculate the loss\n",
        "        loss = loss_func(labels, predictions)\n",
        "    # Get the gradients\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    # Update the weights\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV4t1KDKj1DT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "39bbac0d-ad61-4059-e462-2b8830215cc8"
      },
      "source": [
        "train_model()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: last batch loss = 0.6219\n",
            "Epoch 0: last batch loss = 0.6485\n",
            "Epoch 0: last batch loss = 0.6242\n",
            "Epoch 0: last batch loss = 0.5949\n",
            "Epoch 0: last batch loss = 0.5445\n",
            "Epoch 0: last batch loss = 0.6175\n",
            "Epoch 0: last batch loss = 0.5613\n",
            "Epoch 1: last batch loss = 0.5783\n",
            "Epoch 1: last batch loss = 0.5972\n",
            "Epoch 1: last batch loss = 0.5862\n",
            "Epoch 1: last batch loss = 0.6051\n",
            "Epoch 1: last batch loss = 0.6145\n",
            "Epoch 1: last batch loss = 0.6144\n",
            "Epoch 1: last batch loss = 0.5889\n",
            "Epoch 2: last batch loss = 0.5653\n",
            "Epoch 2: last batch loss = 0.6612\n",
            "Epoch 2: last batch loss = 0.5836\n",
            "Epoch 2: last batch loss = 0.5821\n",
            "Epoch 2: last batch loss = 0.6220\n",
            "Epoch 2: last batch loss = 0.5184\n",
            "Epoch 2: last batch loss = 0.6415\n",
            "Epoch 3: last batch loss = 0.7204\n",
            "Epoch 3: last batch loss = 0.5426\n",
            "Epoch 3: last batch loss = 0.6066\n",
            "Epoch 3: last batch loss = 0.5415\n",
            "Epoch 3: last batch loss = 0.5652\n",
            "Epoch 3: last batch loss = 0.5460\n",
            "Epoch 3: last batch loss = 0.5973\n",
            "Epoch 4: last batch loss = 0.6444\n",
            "Epoch 4: last batch loss = 0.5854\n",
            "Epoch 4: last batch loss = 0.5796\n",
            "Epoch 4: last batch loss = 0.6020\n",
            "Epoch 4: last batch loss = 0.5241\n",
            "Epoch 4: last batch loss = 0.5772\n",
            "Epoch 4: last batch loss = 0.4837\n",
            "Epoch 5: last batch loss = 0.5351\n",
            "Epoch 5: last batch loss = 0.5935\n",
            "Epoch 5: last batch loss = 0.6892\n",
            "Epoch 5: last batch loss = 0.5537\n",
            "Epoch 5: last batch loss = 0.5460\n",
            "Epoch 5: last batch loss = 0.5638\n",
            "Epoch 5: last batch loss = 0.5859\n",
            "Epoch 6: last batch loss = 0.6076\n",
            "Epoch 6: last batch loss = 0.5996\n",
            "Epoch 6: last batch loss = 0.5376\n",
            "Epoch 6: last batch loss = 0.5890\n",
            "Epoch 6: last batch loss = 0.5289\n",
            "Epoch 6: last batch loss = 0.6422\n",
            "Epoch 6: last batch loss = 0.3953\n",
            "Epoch 7: last batch loss = 0.6294\n",
            "Epoch 7: last batch loss = 0.6299\n",
            "Epoch 7: last batch loss = 0.5771\n",
            "Epoch 7: last batch loss = 0.5796\n",
            "Epoch 7: last batch loss = 0.4857\n",
            "Epoch 7: last batch loss = 0.4984\n",
            "Epoch 7: last batch loss = 0.6125\n",
            "Epoch 8: last batch loss = 0.5398\n",
            "Epoch 8: last batch loss = 0.5576\n",
            "Epoch 8: last batch loss = 0.4993\n",
            "Epoch 8: last batch loss = 0.6194\n",
            "Epoch 8: last batch loss = 0.5872\n",
            "Epoch 8: last batch loss = 0.5893\n",
            "Epoch 8: last batch loss = 0.5239\n",
            "Epoch 9: last batch loss = 0.5601\n",
            "Epoch 9: last batch loss = 0.5246\n",
            "Epoch 9: last batch loss = 0.4954\n",
            "Epoch 9: last batch loss = 0.5682\n",
            "Epoch 9: last batch loss = 0.5798\n",
            "Epoch 9: last batch loss = 0.6051\n",
            "Epoch 9: last batch loss = 0.6627\n",
            "It took 1.115654706954956 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIfQh4eEj1Dh",
        "colab_type": "text"
      },
      "source": [
        "Slower!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY45TbSqj1Dj",
        "colab_type": "text"
      },
      "source": [
        "## Model subclassing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY4hMv86j1Dr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv2d_1 = tf.keras.layers.Conv2D(filters=6, \n",
        "                           kernel_size=(3, 3), activation='relu', \n",
        "                           input_shape=(32,32,1))\n",
        "        self.average_pool = tf.keras.layers.AveragePooling2D()\n",
        "        self.conv2d_2 = tf.keras.layers.Conv2D(filters=16, \n",
        "                           kernel_size=(3, 3), activation='relu')\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.fc_1 = tf.keras.layers.Dense(120, activation='relu')\n",
        "        self.fc_2 = tf.keras.layers.Dense(84, activation='relu')\n",
        "        self.out = tf.keras.layers.Dense(10, activation='softmax')\n",
        "        \n",
        "    def call(self, input):\n",
        "        x = self.conv2d_1(input)\n",
        "        x = self.average_pool(x)\n",
        "        x = self.conv2d_2(x)\n",
        "        x = self.average_pool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc_2(self.fc_1(x))\n",
        "        return self.out(x)\n",
        "    \n",
        "lenet = LeNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5pGyWQhj1Dx",
        "colab_type": "text"
      },
      "source": [
        "## Distributed training\n",
        "\n",
        "Currently, for `tf.keras` [MirroredStrategy](https://www.tensorflow.org/guide/distributed_training#mirroredstrategy) works the best (reference: https://www.tensorflow.org/guide/distributed_training#types_of_strategies). We first need to define the strategy with which we want to train our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rl8YvsEKj1D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg6bTq9Bj1EC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5fcf4323-e036-4395-cf06-643c2e0faf41"
      },
      "source": [
        "# Since I don't have multiple GPUs :P\n",
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k37pWSXDj1EN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b1b1d5a5-7c6d-4e56-94d6-8f2639a1b262"
      },
      "source": [
        "# Call the distribution scope context manager\n",
        "with strategy.scope():\n",
        "    # Define a model to fit the above data\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dropout(rate=0.2, input_shape=X.shape[1:]),\n",
        "        tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "        tf.keras.layers.Dropout(rate=0.2),\n",
        "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJgak2Qfj1ET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "3ae17f1d-e0d8-4e42-c84d-b6fabfbdb103"
      },
      "source": [
        "# Train the model\n",
        "model.fit(X, y, epochs=5)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 100 samples\n",
            "Epoch 1/5\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "100/100 [==============================] - 2s 18ms/sample - loss: 0.8513 - accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 0s 265us/sample - loss: 0.7999 - accuracy: 0.3900\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 0s 226us/sample - loss: 0.7113 - accuracy: 0.5200\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 0s 252us/sample - loss: 0.7807 - accuracy: 0.3900\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 0s 224us/sample - loss: 0.7524 - accuracy: 0.5100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f921966cb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}