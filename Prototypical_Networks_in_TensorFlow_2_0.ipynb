{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prototypical Networks in TensorFlow 2.0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayakpaul/TF-2.0-Hacks/blob/master/Prototypical_Networks_in_TensorFlow_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3weO3xt6-i1E",
        "colab_type": "text"
      },
      "source": [
        "## Data gathering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eROAs3aS6wHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/brendenlake/omniglot/raw/master/python/images_background.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d78ikRIV-Y_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/brendenlake/omniglot/raw/master/python/images_evaluation.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL-MdFex8spV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip images_background.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIlL1x9_-bDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip images_evaluation.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCrqYMNr8_8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import multiprocessing as mp\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxb328gS9gJp",
        "colab_type": "text"
      },
      "source": [
        "## Data reading and augmentation\n",
        "The Omniglot data set is designed for developing more human-like learning algorithms. It contains 1623 different handwritten characters from 50 different alphabets. Then to increase the number of classes, all the images are rotated by 90, 180 and 270 degrees and each rotation resulted in one more class. Hence the total count of classes reached to 6492(1623 * 4) classes. We split images of 4200 classes to training data and the rest went to test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdMcXOli9bFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.listdir('images_background/')\n",
        "datax = np.array([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEssKQ6f9z73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_rotate(img, angle):\n",
        "    \"\"\"\n",
        "    Image rotation at certain angle. It is used for data augmentation \n",
        "    \"\"\"\n",
        "    rows,cols, _ = img.shape\n",
        "    M = cv2.getRotationMatrix2D((cols/2 ,rows/2),angle,1)\n",
        "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
        "    return np.expand_dims(dst, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-b0wy9J953l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_alphabets(alphabet_directory, directory):\n",
        "    \"\"\"\n",
        "    Reads all the characters from alphabet_directory and augment each image with 90, 180, 270 degrees of rotation.\n",
        "    \"\"\"\n",
        "    datax = None\n",
        "    datay = []\n",
        "    characters = os.listdir(alphabet_directory)\n",
        "    for character in characters:\n",
        "        images = os.listdir(alphabet_directory + character + '/')\n",
        "        for img in images:\n",
        "            image = cv2.resize(cv2.imread(alphabet_directory + character + '/' + img), (28,28))\n",
        "            image90 = image_rotate(image, 90)\n",
        "            image180 = image_rotate(image, 180)\n",
        "            image270 = image_rotate(image, 270)\n",
        "            image = np.expand_dims(image, 0)\n",
        "            if datax is None:\n",
        "                datax = np.vstack([image, image90, image180, image270])\n",
        "            else:\n",
        "                datax = np.vstack([datax, image, image90, image180, image270])\n",
        "            datay.append(directory + '_' + character + '_0')\n",
        "            datay.append(directory + '_' + character + '_90')\n",
        "            datay.append(directory + '_' + character + '_180')\n",
        "            datay.append(directory + '_' + character + '_270')\n",
        "    return datax, np.array(datay)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j4URJB_98pC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_images(base_directory):\n",
        "    \"\"\"\n",
        "    Used multithreading for data reading to decrease the reading time drastically\n",
        "    \"\"\"\n",
        "    datax = None\n",
        "    datay = []\n",
        "    pool = mp.Pool(mp.cpu_count())\n",
        "    results = [pool.apply(read_alphabets, args=(base_directory + '/' + directory + '/', directory, )) for directory in os.listdir(base_directory)]\n",
        "    pool.close()\n",
        "    for result in results:\n",
        "        if datax is None:\n",
        "            datax = result[0]\n",
        "            datay = result[1]\n",
        "        else:\n",
        "            datax = np.vstack([datax, result[0]])\n",
        "            datay = np.concatenate([datay, result[1]])\n",
        "    return datax, datay"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPpRsOd-9_A7",
        "colab_type": "code",
        "outputId": "dc651570-e635-445c-c94b-4e481f4d4535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%time trainx, trainy = read_images('images_background/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 783 ms, sys: 464 ms, total: 1.25 s\n",
            "Wall time: 16.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvFXXdoT-Ew8",
        "colab_type": "code",
        "outputId": "30045f40-2371-4fa1-e232-34391595b4a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%time testx, testy = read_images('images_evaluation/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 348 ms, sys: 346 ms, total: 694 ms\n",
            "Wall time: 10.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR7DaBrh-uil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert(trainx.shape[0] == trainy.shape[0])\n",
        "assert(testx.shape[0] == testy.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnIaQ2_O_B1M",
        "colab_type": "text"
      },
      "source": [
        "## Building the network in TensorFlow 2.0 using `tf.keras`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tgJ2u9H-yDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-beta1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu8Z5086_Low",
        "colab_type": "code",
        "outputId": "d20312ff-e8ca-4885-b005-b855e2370fc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV02b54s_qEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR0E241E_rzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(keras.Model):\n",
        "    \"\"\"\n",
        "    Image2Vector CNN which takes image of dimension (28x28x3) and return column vector length 64\n",
        "    \"\"\"\n",
        "    def sub_block(self, out_channels=64, kernel_size=(3,3)):\n",
        "        block = keras.models.Sequential([\n",
        "                    keras.layers.Conv2D(filters=out_channels, \\\n",
        "                        kernel_size=kernel_size, input_shape=(28, 28, 3)),\n",
        "                    keras.layers.BatchNormalization(),\n",
        "                    keras.layers.ReLU(),\n",
        "                    keras.layers.MaxPool2D(pool_size=(2,2))\n",
        "        ])\n",
        "        return block\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.convnet1 = self.sub_block()\n",
        "        self.convnet2 = self.sub_block()\n",
        "        self.convnet3 = self.sub_block()\n",
        "        self.convnet4 = self.sub_block()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.convnet1(x)\n",
        "        x = self.convnet2(x)\n",
        "        x = self.convnet3(x)\n",
        "        x = self.convnet4(x)\n",
        "        x = keras.layers.Flatten()(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jfN3KEYbQuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEKvU-M_bN0l",
        "colab_type": "text"
      },
      "source": [
        "To be continued.\n",
        "\n",
        "https://blog.floydhub.com/n-shot-learning/"
      ]
    }
  ]
}