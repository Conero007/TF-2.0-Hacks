{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFRecords with tf.data - Advanced.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP8VnYU09MHZ",
        "colab_type": "text"
      },
      "source": [
        "This notebook shows how to build TFRecords from a custom image classification dataset and how to use the TFRecords to train a deep learning model in `tf.keras.` This notebook has some major sections:\n",
        "- Writing TFRecords\n",
        "- Loading in the TFRecords\n",
        "- Model building\n",
        "- Training models with TFRecords\n",
        "\n",
        "Acknowledgements: [Martin GÃ¶rner](https://twitter.com/martin_gorner) & his amazing [tutorial notebook](https://nbviewer.jupyter.org/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/keras_flowers_gputputpupod_tf2.1.ipynb). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTCzvn_q-_ss",
        "colab_type": "text"
      },
      "source": [
        "## Initial setup and imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-A6kC0XpNhg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f627cbea-3ba6-4c59-e386-917eb345b230"
      },
      "source": [
        "# Select TensorFlow 2.0 environment\n",
        "# This will only work in Colab\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOWBcT9MpWlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from imutils import paths\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD-Xft4tBJ3B",
        "colab_type": "code",
        "outputId": "bc64ca98-ce32-46fe-e452-94dcf65aacc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVwKyVBW9PX1",
        "colab_type": "text"
      },
      "source": [
        "## Data gathering and inspection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H5VUQOkpZRi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a534b751-185d-4349-db0f-b3fb156cd948"
      },
      "source": [
        "# Get the flowers' dataset\n",
        "flowers = tf.keras.utils.get_file(\n",
        "    'flower_photos',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "    untar=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228818944/228813984 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnlh2R4XpbE8",
        "colab_type": "code",
        "outputId": "1b784e1f-ce00-435d-df9a-4bd496dfe978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# We have got five different classes\n",
        "!ls {flowers}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "daisy  dandelion  LICENSE.txt  roses  sunflowers  tulips\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vmdc1F4r_jlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASSES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B04y2iYd3txo",
        "colab_type": "code",
        "outputId": "b141174a-f961-4867-8881-b5a24e6f38ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# There are a total of ____ images\n",
        "total_data = len(list(paths.list_images(flowers)))\n",
        "total_data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3670"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_6BDMiKpdD2",
        "colab_type": "code",
        "outputId": "6c58f462-c43b-4048-fa80-ac81e31b0b38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Gather all the image paths\n",
        "dataset = tf.data.Dataset.list_files(str(pathlib.Path(flowers)/'*/*'), seed=666)\n",
        "for filename in dataset.take(5):\n",
        "    print(filename.numpy())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'/root/.keras/datasets/flower_photos/tulips/14087425312_2b5846b570_n.jpg'\n",
            "b'/root/.keras/datasets/flower_photos/sunflowers/3846717708_ea11383ed8.jpg'\n",
            "b'/root/.keras/datasets/flower_photos/sunflowers/244074259_47ce6d3ef9.jpg'\n",
            "b'/root/.keras/datasets/flower_photos/dandelion/19812060274_c432f603db.jpg'\n",
            "b'/root/.keras/datasets/flower_photos/sunflowers/3062794421_295f8c2c4e.jpg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBh_z6AI9fX3",
        "colab_type": "text"
      },
      "source": [
        "Note that the above paths are byte-strings not text strings. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZrfJLKO9jTt",
        "colab_type": "text"
      },
      "source": [
        "## Prepare helper functions for writing TFRecords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Tt-4JEp2g-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to read the image from the path,\n",
        "# parse its labels, cast the pixel pvalues to float,\n",
        "# and resize the image\n",
        "def parse_image(filename):\n",
        "    parts = tf.strings.split(filename, '/')\n",
        "    label = parts[-2]\n",
        "\n",
        "    image = tf.io.read_file(filename)\n",
        "    image = tf.image.decode_jpeg(image)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, [128, 128])\n",
        "    return (image, label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-Q2R279qj3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AUTOTUNE makes it easier to make the parallelization dynamic\n",
        "dataset = dataset.map(parse_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgH1z7CSqsQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Images are byte-strings\n",
        "def _bytestring_feature(list_of_bytestrings):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))\n",
        "\n",
        "# Classes would be integers\n",
        "def _int_feature(list_of_ints): \n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urZnxH6Rq_rP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that prepares a record for the tfrecord file\n",
        "# A record contains the image and its label\n",
        "def to_tfrecord(img_bytes, label):  \n",
        "    class_num = np.argmax(np.array(CLASSES)==label) \n",
        "    feature = {\n",
        "      \"image\": _bytestring_feature([img_bytes]), \n",
        "      \"class\": _int_feature([class_num]),             \n",
        "    }\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKk8y-Mstnut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need to convert the image to byte strings\n",
        "def recompress_image(image, label):\n",
        "    image = tf.cast(image, tf.uint8)\n",
        "    image = tf.image.encode_jpeg(image, optimize_size=True, chroma_downsampling=False)\n",
        "    return (image, label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRvcDZxZttBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make full use of `map`\n",
        "dataset = dataset.map(recompress_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "dataset = dataset.batch(32) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPalgVD1rNpk",
        "colab_type": "code",
        "outputId": "cd7b0b9c-3cb9-4276-bce3-e9303a57057d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Prepare tfrecords\n",
        "for shard, (image, label) in enumerate(dataset):\n",
        "    shard_size = image.numpy().shape[0]\n",
        "    filename = \"flowers-\" + \"{:02d}-{}.tfrec\".format(shard, shard_size)\n",
        "  \n",
        "    with tf.io.TFRecordWriter(filename) as out_file:\n",
        "        for i in range(shard_size):\n",
        "            example = to_tfrecord(image.numpy()[i],label.numpy()[i])\n",
        "            out_file.write(example.SerializeToString())\n",
        "        print(\"Wrote file {} containing {} records\".format(filename, shard_size))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrote file flowers-00-32.tfrec containing 32 records\n",
            "Wrote file flowers-01-32.tfrec containing 32 records\n",
            "Wrote file flowers-02-32.tfrec containing 32 records\n",
            "Wrote file flowers-03-32.tfrec containing 32 records\n",
            "Wrote file flowers-04-32.tfrec containing 32 records\n",
            "Wrote file flowers-05-32.tfrec containing 32 records\n",
            "Wrote file flowers-06-32.tfrec containing 32 records\n",
            "Wrote file flowers-07-32.tfrec containing 32 records\n",
            "Wrote file flowers-08-32.tfrec containing 32 records\n",
            "Wrote file flowers-09-32.tfrec containing 32 records\n",
            "Wrote file flowers-10-32.tfrec containing 32 records\n",
            "Wrote file flowers-11-32.tfrec containing 32 records\n",
            "Wrote file flowers-12-32.tfrec containing 32 records\n",
            "Wrote file flowers-13-32.tfrec containing 32 records\n",
            "Wrote file flowers-14-32.tfrec containing 32 records\n",
            "Wrote file flowers-15-32.tfrec containing 32 records\n",
            "Wrote file flowers-16-32.tfrec containing 32 records\n",
            "Wrote file flowers-17-32.tfrec containing 32 records\n",
            "Wrote file flowers-18-32.tfrec containing 32 records\n",
            "Wrote file flowers-19-32.tfrec containing 32 records\n",
            "Wrote file flowers-20-32.tfrec containing 32 records\n",
            "Wrote file flowers-21-32.tfrec containing 32 records\n",
            "Wrote file flowers-22-32.tfrec containing 32 records\n",
            "Wrote file flowers-23-32.tfrec containing 32 records\n",
            "Wrote file flowers-24-32.tfrec containing 32 records\n",
            "Wrote file flowers-25-32.tfrec containing 32 records\n",
            "Wrote file flowers-26-32.tfrec containing 32 records\n",
            "Wrote file flowers-27-32.tfrec containing 32 records\n",
            "Wrote file flowers-28-32.tfrec containing 32 records\n",
            "Wrote file flowers-29-32.tfrec containing 32 records\n",
            "Wrote file flowers-30-32.tfrec containing 32 records\n",
            "Wrote file flowers-31-32.tfrec containing 32 records\n",
            "Wrote file flowers-32-32.tfrec containing 32 records\n",
            "Wrote file flowers-33-32.tfrec containing 32 records\n",
            "Wrote file flowers-34-32.tfrec containing 32 records\n",
            "Wrote file flowers-35-32.tfrec containing 32 records\n",
            "Wrote file flowers-36-32.tfrec containing 32 records\n",
            "Wrote file flowers-37-32.tfrec containing 32 records\n",
            "Wrote file flowers-38-32.tfrec containing 32 records\n",
            "Wrote file flowers-39-32.tfrec containing 32 records\n",
            "Wrote file flowers-40-32.tfrec containing 32 records\n",
            "Wrote file flowers-41-32.tfrec containing 32 records\n",
            "Wrote file flowers-42-32.tfrec containing 32 records\n",
            "Wrote file flowers-43-32.tfrec containing 32 records\n",
            "Wrote file flowers-44-32.tfrec containing 32 records\n",
            "Wrote file flowers-45-32.tfrec containing 32 records\n",
            "Wrote file flowers-46-32.tfrec containing 32 records\n",
            "Wrote file flowers-47-32.tfrec containing 32 records\n",
            "Wrote file flowers-48-32.tfrec containing 32 records\n",
            "Wrote file flowers-49-32.tfrec containing 32 records\n",
            "Wrote file flowers-50-32.tfrec containing 32 records\n",
            "Wrote file flowers-51-32.tfrec containing 32 records\n",
            "Wrote file flowers-52-32.tfrec containing 32 records\n",
            "Wrote file flowers-53-32.tfrec containing 32 records\n",
            "Wrote file flowers-54-32.tfrec containing 32 records\n",
            "Wrote file flowers-55-32.tfrec containing 32 records\n",
            "Wrote file flowers-56-32.tfrec containing 32 records\n",
            "Wrote file flowers-57-32.tfrec containing 32 records\n",
            "Wrote file flowers-58-32.tfrec containing 32 records\n",
            "Wrote file flowers-59-32.tfrec containing 32 records\n",
            "Wrote file flowers-60-32.tfrec containing 32 records\n",
            "Wrote file flowers-61-32.tfrec containing 32 records\n",
            "Wrote file flowers-62-32.tfrec containing 32 records\n",
            "Wrote file flowers-63-32.tfrec containing 32 records\n",
            "Wrote file flowers-64-32.tfrec containing 32 records\n",
            "Wrote file flowers-65-32.tfrec containing 32 records\n",
            "Wrote file flowers-66-32.tfrec containing 32 records\n",
            "Wrote file flowers-67-32.tfrec containing 32 records\n",
            "Wrote file flowers-68-32.tfrec containing 32 records\n",
            "Wrote file flowers-69-32.tfrec containing 32 records\n",
            "Wrote file flowers-70-32.tfrec containing 32 records\n",
            "Wrote file flowers-71-32.tfrec containing 32 records\n",
            "Wrote file flowers-72-32.tfrec containing 32 records\n",
            "Wrote file flowers-73-32.tfrec containing 32 records\n",
            "Wrote file flowers-74-32.tfrec containing 32 records\n",
            "Wrote file flowers-75-32.tfrec containing 32 records\n",
            "Wrote file flowers-76-32.tfrec containing 32 records\n",
            "Wrote file flowers-77-32.tfrec containing 32 records\n",
            "Wrote file flowers-78-32.tfrec containing 32 records\n",
            "Wrote file flowers-79-32.tfrec containing 32 records\n",
            "Wrote file flowers-80-32.tfrec containing 32 records\n",
            "Wrote file flowers-81-32.tfrec containing 32 records\n",
            "Wrote file flowers-82-32.tfrec containing 32 records\n",
            "Wrote file flowers-83-32.tfrec containing 32 records\n",
            "Wrote file flowers-84-32.tfrec containing 32 records\n",
            "Wrote file flowers-85-32.tfrec containing 32 records\n",
            "Wrote file flowers-86-32.tfrec containing 32 records\n",
            "Wrote file flowers-87-32.tfrec containing 32 records\n",
            "Wrote file flowers-88-32.tfrec containing 32 records\n",
            "Wrote file flowers-89-32.tfrec containing 32 records\n",
            "Wrote file flowers-90-32.tfrec containing 32 records\n",
            "Wrote file flowers-91-32.tfrec containing 32 records\n",
            "Wrote file flowers-92-32.tfrec containing 32 records\n",
            "Wrote file flowers-93-32.tfrec containing 32 records\n",
            "Wrote file flowers-94-32.tfrec containing 32 records\n",
            "Wrote file flowers-95-32.tfrec containing 32 records\n",
            "Wrote file flowers-96-32.tfrec containing 32 records\n",
            "Wrote file flowers-97-32.tfrec containing 32 records\n",
            "Wrote file flowers-98-32.tfrec containing 32 records\n",
            "Wrote file flowers-99-32.tfrec containing 32 records\n",
            "Wrote file flowers-100-32.tfrec containing 32 records\n",
            "Wrote file flowers-101-32.tfrec containing 32 records\n",
            "Wrote file flowers-102-32.tfrec containing 32 records\n",
            "Wrote file flowers-103-32.tfrec containing 32 records\n",
            "Wrote file flowers-104-32.tfrec containing 32 records\n",
            "Wrote file flowers-105-32.tfrec containing 32 records\n",
            "Wrote file flowers-106-32.tfrec containing 32 records\n",
            "Wrote file flowers-107-32.tfrec containing 32 records\n",
            "Wrote file flowers-108-32.tfrec containing 32 records\n",
            "Wrote file flowers-109-32.tfrec containing 32 records\n",
            "Wrote file flowers-110-32.tfrec containing 32 records\n",
            "Wrote file flowers-111-32.tfrec containing 32 records\n",
            "Wrote file flowers-112-32.tfrec containing 32 records\n",
            "Wrote file flowers-113-32.tfrec containing 32 records\n",
            "Wrote file flowers-114-22.tfrec containing 22 records\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gscKd2I_C0O",
        "colab_type": "text"
      },
      "source": [
        "## Loading TFRecords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdnEv6HCxw09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to read the TFRecords, segregate the images and labels\n",
        "def read_tfrecord(example):\n",
        "    features = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), \n",
        "        \"class\": tf.io.FixedLenFeature([], tf.int64)\n",
        "    }\n",
        "    \n",
        "    example = tf.io.parse_single_example(example, features)\n",
        "    image = tf.image.decode_jpeg(example['image'], channels=3)\n",
        "    image = tf.cast(image, tf.float32) / 255.0  \n",
        "    image = tf.reshape(image, [128, 128, 3]) \n",
        "    class_label = tf.cast(example['class'], tf.int32)\n",
        "    \n",
        "    return (image, class_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1h2Wwycyj0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TFRecords and create tf.data.Dataset\n",
        "def load_dataset(filenames):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=16) \n",
        "    dataset = dataset.map(read_tfrecord, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuBf9OaQ4-tT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need this to derive steps\n",
        "def count_data_items(filenames):\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17fGRmxZy9Bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch, shuffle and repeat the dataset and pre-fetch it\n",
        "# well before the current epoch ends\n",
        "def batch_dataset(filenames, batch_size, train):\n",
        "    dataset = load_dataset(filenames)\n",
        "    n = count_data_items(filenames)\n",
        "    \n",
        "    if train:\n",
        "        dataset = dataset.shuffle(buffer_size=1000).repeat()\n",
        "    else:\n",
        "        dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE) \n",
        "    return (dataset, n//batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMh7pW7Yr-8q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f440d71b-c1e9-4dc1-9b17-6caa7f178c77"
      },
      "source": [
        "tfrecord_pattern = \"*.tfrec\"\n",
        "filenames = tf.io.gfile.glob(tfrecord_pattern)\n",
        "filenames[:10]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./flowers-22-32.tfrec',\n",
              " './flowers-57-32.tfrec',\n",
              " './flowers-65-32.tfrec',\n",
              " './flowers-16-32.tfrec',\n",
              " './flowers-94-32.tfrec',\n",
              " './flowers-18-32.tfrec',\n",
              " './flowers-71-32.tfrec',\n",
              " './flowers-46-32.tfrec',\n",
              " './flowers-84-32.tfrec',\n",
              " './flowers-112-32.tfrec']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEonZR5C_bNj",
        "colab_type": "text"
      },
      "source": [
        "## Model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Aqh7bmf3fWE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f1ee62fd-71b9-4d74-aa29-2a1aef555f11"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "split = len(filenames) - int(len(filenames) * 0.2)\n",
        "train_filenames = filenames[:split]\n",
        "valid_filenames = filenames[split:]\n",
        "\n",
        "training_dataset, steps_per_epoch = batch_dataset(train_filenames, BATCH_SIZE, True)\n",
        "validation_dataset, validation_steps = batch_dataset(valid_filenames, BATCH_SIZE, False)\n",
        "\n",
        "print(\"TRAINING   IMAGES: \", count_data_items(train_filenames), \", STEPS PER EPOCH: \", steps_per_epoch)\n",
        "print(\"VALIDATION IMAGES: \", count_data_items(valid_filenames), \", STEPS PER EPOCH: \", validation_steps)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING   IMAGES:  2934 , STEPS PER EPOCH:  45\n",
            "VALIDATION IMAGES:  736 , STEPS PER EPOCH:  11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcP2eivD7DTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_training_model():\n",
        "    baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
        "        input_tensor=Input(shape=(128, 128, 3)))\n",
        "\n",
        "    headModel = baseModel.output\n",
        "    headModel = Flatten(name=\"flatten\")(headModel)\n",
        "    headModel = Dense(512, activation=\"relu\")(headModel)\n",
        "    headModel = Dropout(0.5)(headModel)\n",
        "    headModel = Dense(5, activation=\"softmax\")(headModel)\n",
        "\n",
        "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "    for layer in baseModel.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    opt = SGD(lr=1e-4, momentum=0.9)\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,\n",
        "        metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZPPeT-E_d0R",
        "colab_type": "text"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-8kRA7R8qMO",
        "colab_type": "code",
        "outputId": "153b57ef-9805-41f9-a5c2-a3a5d86d26d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model = get_training_model()\n",
        "model.fit(training_dataset, \n",
        "         steps_per_epoch=steps_per_epoch,\n",
        "         validation_data=validation_dataset,\n",
        "         validation_steps=validation_steps,\n",
        "         epochs=5)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "Train for 45 steps, validate for 11 steps\n",
            "Epoch 1/5\n",
            "45/45 [==============================] - 17s 373ms/step - loss: 0.2464 - accuracy: 0.9118 - val_loss: 2.9406e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "45/45 [==============================] - 10s 222ms/step - loss: 7.3506e-04 - accuracy: 1.0000 - val_loss: 2.5068e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "45/45 [==============================] - 10s 226ms/step - loss: 6.9423e-04 - accuracy: 1.0000 - val_loss: 2.3780e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "45/45 [==============================] - 10s 223ms/step - loss: 7.1199e-04 - accuracy: 1.0000 - val_loss: 2.2517e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "45/45 [==============================] - 10s 222ms/step - loss: 6.7326e-04 - accuracy: 1.0000 - val_loss: 2.1385e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3d20160b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWTQ3IL6_64R",
        "colab_type": "text"
      },
      "source": [
        "## Explore more:\n",
        "\n",
        "- https://www.tensorflow.org/tutorials/load_data/tfrecord\n",
        "- https://codelabs.developers.google.com/codelabs/keras-flowers-data/\n",
        "- https://medium.com/ymedialabs-innovation/how-to-use-tfrecord-with-datasets-and-iterators-in-tensorflow-with-code-samples-ffee57d298af"
      ]
    }
  ]
}